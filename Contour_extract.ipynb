{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract contours from GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfile = \"./Inputs/coastal_polygons.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ogr\n",
    "import osr\n",
    "import datacube\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dea_datahandling import load_ard\n",
    "from dea_datahandling import mostcommon_crs\n",
    "from dea_bandindices import calculate_indices\n",
    "from dea_coastaltools import tidal_tag\n",
    "from dea_spatialtools import contour_extract\n",
    "from dea_plotting import display_map\n",
    "from dea_plotting import rgb\n",
    "from dea_plotting import map_shapefile\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import fiona\n",
    "from shapely.geometry import mapping\n",
    "from shapely.ops import nearest_points\n",
    "from shapely.geometry import Point, LineString, MultiPoint\n",
    "import geopandas as gpd\n",
    "\n",
    "dc = datacube.Datacube(app='erosion_contours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_regress(row, x_vals, x_labels, std_dev=3):\n",
    "    \n",
    "    # Extract x (time) and y (distance) values\n",
    "    x = x_vals\n",
    "    y = row.values[1:].astype(np.float)\n",
    "    \n",
    "    # Drop NAN rows\n",
    "    xy_df = np.vstack([x, y]).T\n",
    "    is_valid = ~np.isnan(xy_df).any(axis=1)\n",
    "    xy_df = xy_df[is_valid]\n",
    "    valid_labels = x_labels[is_valid]\n",
    "    \n",
    "    # Remove outliers\n",
    "    outlier_bool = (np.abs(stats.zscore(xy_df)) < float(std_dev)).all(axis=1)\n",
    "    xy_df = xy_df[outlier_bool]\n",
    "        \n",
    "    # Compute linear regression\n",
    "    lin_reg = stats.linregress(x=xy_df[:,0], \n",
    "                               y=xy_df[:,1])\n",
    "    \n",
    "    # Return slope, p-values and list of outlier years excluded from regression   \n",
    "    return pd.Series({'slope': np.round(lin_reg.slope, 2), \n",
    "                      'pvalue': np.round(lin_reg.pvalue, 3),\n",
    "                      'outliers': str(valid_labels[~outlier_bool]).replace('[', '').replace(']', '')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(feature):\n",
    "    \n",
    "    # Extract polygon to determine load range for data\n",
    "    polygon = ogr.CreateGeometryFromJson(str(feature['geometry']))\n",
    "\n",
    "    source = osr.SpatialReference()\n",
    "    source.ImportFromEPSG(4326)\n",
    "\n",
    "    target = osr.SpatialReference()\n",
    "    target.ImportFromEPSG(3577)\n",
    "\n",
    "    transform = osr.CoordinateTransformation(source, target)\n",
    "    polygon.Transform(transform)\n",
    "    \n",
    "    poly_envelope = polygon.GetEnvelope()\n",
    "    minX, maxX, minY, maxY = poly_envelope\n",
    "    \n",
    "    # Set parameters for dc load\n",
    "    x_range = (minX, maxX)\n",
    "    y_range = (minY, maxY)\n",
    "    time_range = ('2000', '2018')\n",
    "    crs = \"EPSG:3577\"\n",
    "    res = (-30, 30)\n",
    "    tide_range = (0.50, 1.00)\n",
    "\n",
    "    products = ['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3']\n",
    "    measurements = ['nbart_red', 'nbart_green', 'nbart_blue', 'nbart_swir_1']\n",
    "    \n",
    "    # Construct query\n",
    "    query = {\n",
    "    'y': y_range,\n",
    "    'x': x_range,\n",
    "    'time': time_range,\n",
    "    'measurements': measurements,\n",
    "    'crs': crs,\n",
    "    'output_crs': crs,\n",
    "    'resolution': res\n",
    "    }\n",
    "\n",
    "    landsat_ds = load_ard(\n",
    "        dc=dc,\n",
    "        products=products,\n",
    "        group_by='solar_day',\n",
    "        **query\n",
    "    )\n",
    "    \n",
    "    # Calculate MNDWI\n",
    "    landsat_ds = calculate_indices(landsat_ds, index='MNDWI', \n",
    "                               collection='ga_ls_3')\n",
    "    \n",
    "    # Calculate tides for each timestep in the satellite dataset\n",
    "    landsat_ds = tidal_tag(ds=landsat_ds, tidepost_lat=None, tidepost_lon=None)\n",
    "    \n",
    "    # Calculate the min and max tide heights to include based on the % range\n",
    "    min_tide, max_tide = landsat_ds.tide_height.quantile(tide_range)\n",
    "    \n",
    "    # Keep timesteps larger than the min tide, and smaller than the max tide\n",
    "    landsat_filtered = landsat_ds.sel(time=(landsat_ds.tide_height > min_tide) &\n",
    "                                           (landsat_ds.tide_height <= max_tide))\n",
    "    \n",
    "    time_step = '1Y'\n",
    "\n",
    "    # Combine into summary images by `time_step`\n",
    "    landsat_summaries = (landsat_filtered.MNDWI\n",
    "                         .compute()\n",
    "                         .resample(time=time_step, closed='left')\n",
    "                         .median('time'))\n",
    "    \n",
    "    # Set up attributes to assign to each waterline\n",
    "    attribute_data = {'time': [str(i)[0:10] for i in landsat_summaries.time.values]}\n",
    "    attribute_dtypes = {'time': 'str'}\n",
    "\n",
    "    # Extract waterline contours for the '0' water index threshold:\n",
    "    contour_gdf = contour_extract(\n",
    "        z_values=[0],\n",
    "        ds_array=landsat_summaries,\n",
    "        ds_crs=landsat_ds.crs,\n",
    "        ds_affine=landsat_ds.geobox.transform,\n",
    "        output_shp=f'Outputs/contours.shp',\n",
    "        attribute_data=attribute_data,\n",
    "        attribute_dtypes=attribute_dtypes,\n",
    "        min_vertices=50)\n",
    "    \n",
    "    contour_gdf.to_crs(epsg=4326)\n",
    "    \n",
    "    return(contour_gdf, landsat_ds, landsat_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rateofchange(contour_gdf, landsat_ds, landsat_summaries):\n",
    "    # Set annual shoreline to use as a baseline\n",
    "    baseline_year = contour_gdf.index[0]\n",
    "    baseline_contour = contour_gdf.loc[baseline_year].geometry\n",
    "\n",
    "    # Set up output shapefile\n",
    "    schema = {'geometry': 'Point','properties': {'id': 'int'}}\n",
    "    baseline_points_shp = f'Outputs/test_statistics.shp' \n",
    "\n",
    "    with fiona.open(baseline_points_shp, 'w', 'ESRI Shapefile', schema, crs=contour_gdf.crs) as output:\n",
    "\n",
    "        # create points every 100 meters along the line\n",
    "        for i, distance in enumerate(range(0, int(baseline_contour.length), 100)):\n",
    "             point = baseline_contour.interpolate(distance)   \n",
    "             output.write({'geometry': mapping(point), 'properties': {'id': i}})\n",
    "            \n",
    "    # Read points in as geopandas\n",
    "    points_gdf = gpd.read_file(baseline_points_shp)\n",
    "\n",
    "    # Copy geometry to baseline point\n",
    "    points_gdf['p_baseline'] = points_gdf.geometry\n",
    "    baseline_x_vals = points_gdf.geometry.x\n",
    "    baseline_y_vals = points_gdf.geometry.y\n",
    "\n",
    "    # Get array of water index values for baseline time period \n",
    "    baseline_array = landsat_summaries.isel(time = baseline_year)\n",
    "    \n",
    "    # Iterate through all comparison years in contour gdf\n",
    "    for comp_year in contour_gdf.index.unique().values:\n",
    "\n",
    "        # Set comparison contour\n",
    "        comp_contour = contour_gdf.loc[comp_year].geometry\n",
    "\n",
    "        # Find nearest point on comparison contour\n",
    "        points_gdf[f'p_{comp_year}'] = points_gdf.apply(lambda x: \n",
    "                                                        nearest_points(x.p_baseline, comp_contour)[1], axis=1)\n",
    "\n",
    "        # Compute distance between baseline and comparison year points\n",
    "        points_gdf[f'{comp_year}'] = points_gdf.apply(lambda x: x.geometry.distance(x[f'p_{comp_year}']), axis=1)\n",
    "\n",
    "        # Extract comparison array\n",
    "        comp_array = landsat_summaries.isel(time = comp_year)\n",
    "\n",
    "        # Convert baseline and comparison year points to geoseries to allow easy access to x and y coords\n",
    "        comp_x_vals = gpd.GeoSeries(points_gdf[f'p_{comp_year}']).x\n",
    "        comp_y_vals = gpd.GeoSeries(points_gdf[f'p_{comp_year}']).y\n",
    "\n",
    "        # Sample NDWI values from arrays based on baseline and comparison points\n",
    "        baseline_x_vals = xr.DataArray(baseline_x_vals, dims='z')\n",
    "        baseline_y_vals = xr.DataArray(baseline_y_vals, dims='z')\n",
    "        comp_x_vals = xr.DataArray(comp_x_vals, dims='z')\n",
    "        comp_y_vals = xr.DataArray(comp_y_vals, dims='z')   \n",
    "        points_gdf['index_comp_p1'] = comp_array.interp(x=baseline_x_vals, y=baseline_y_vals)\n",
    "        points_gdf['index_baseline_p2'] = baseline_array.interp(x=comp_x_vals, y=comp_y_vals)\n",
    "\n",
    "        # Compute directionality of change (negative = erosion, positive = accretion)    \n",
    "        points_gdf['loss_gain'] = (points_gdf.index_baseline_p2 > points_gdf.index_comp_p1).astype(int).replace(to_replace=0, value=-1)\n",
    "        points_gdf[f'{comp_year}'] = points_gdf[f'{comp_year}'] * points_gdf.loss_gain\n",
    "\n",
    "    # Get list of cols to keep\n",
    "    cols_to_keep = ['geometry'] + [str(val) for val in contour_gdf.index.unique().values]\n",
    "\n",
    "    # Keep required columns\n",
    "    points_gdf = points_gdf[cols_to_keep]\n",
    "    points_gdf = points_gdf.round(2)\n",
    "    \n",
    "    x_years = np.array([int(i[:4]) for i in points_gdf.columns[1:]])\n",
    "    \n",
    "    # Compute change rates\n",
    "    rate_out = points_gdf.apply(lambda x: change_regress(x, x_vals = x_years, x_labels = x_years, std_dev=3), axis=1)\n",
    "\n",
    "    points_gdf[['mov_rate', 'mov_sig', 'mov_outl']] = rate_out\n",
    "    \n",
    "    # Set CRS\n",
    "    points_gdf.crs = str(landsat_ds.crs)\n",
    "\n",
    "    # Sort by descending absolute value and export\n",
    "    points_gdf.reindex(points_gdf.mov_rate.abs().sort_values().index).to_file(baseline_points_shp)\n",
    "    \n",
    "    points_gdf = points_gdf[['geometry', 'mov_rate']]\n",
    "    points_gdf.crs = {'init' :'epsg:3577'}\n",
    "    points_gdf = points_gdf.to_crs({'init': 'epsg:4326'})\n",
    "    \n",
    "    return(points_gdf)\n",
    "\n",
    "    #points_gdf.to_file('Outputs/contours_rateofchange.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jsonfile) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for i, feature in enumerate(data['features']):\n",
    "    contour, ds, ds_summary = get_contours(feature)\n",
    "    contour.to_file(f'Outputs/contours_{i}.geojson', driver='GeoJSON')\n",
    "    \n",
    "    points = get_rateofchange(contour, ds, ds_summary)\n",
    "    rate_of_change_file = f'Outputs/contours_rateofchange_{i}.geojson'\n",
    "    points.to_file(rate_of_change_file, driver='GeoJSON')\n",
    "    \n",
    "    properties_dict = {'mov_rate': f'{np.mean(abs(points.mov_rate)).round(2)}',\n",
    "                  'mov_points_file': 'contours_rateofchange.geojson'}\n",
    "\n",
    "    data['features'][i]['properties'] = properties_dict\n",
    "\n",
    "with open('Outputs/updated_polygons.geojson', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
