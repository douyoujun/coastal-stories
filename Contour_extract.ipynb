{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract contours from GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfile = \"./Inputs/coastal_polygons.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ogr\n",
    "import osr\n",
    "import datacube\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dea_datahandling import load_ard\n",
    "from dea_datahandling import mostcommon_crs\n",
    "from dea_bandindices import calculate_indices\n",
    "from dea_coastaltools import tidal_tag\n",
    "from dea_spatialtools import contour_extract\n",
    "from dea_plotting import display_map\n",
    "from dea_plotting import rgb\n",
    "from dea_plotting import map_shapefile\n",
    "import xarray as xr\n",
    "\n",
    "dc = datacube.Datacube(app='erosion_contours')\n",
    "\n",
    "with open(jsonfile) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in data['features']:\n",
    "#     print(feature['geometry']['type'])\n",
    "#     print(feature['geometry']['coordinates'])\n",
    "\n",
    "feature = data['features'][0]\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = ogr.CreateGeometryFromJson(str(feature['geometry']))\n",
    "\n",
    "source = osr.SpatialReference()\n",
    "source.ImportFromEPSG(4326)\n",
    "\n",
    "target = osr.SpatialReference()\n",
    "target.ImportFromEPSG(3577)\n",
    "\n",
    "transform = osr.CoordinateTransformation(source, target)\n",
    "polygon.Transform(transform)\n",
    "\n",
    "print(polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_envelope = polygon.GetEnvelope()\n",
    "minX, maxX, minY, maxY = poly_envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dc.load params\n",
    "x_range = (minX, maxX)\n",
    "y_range = (minY, maxY)\n",
    "time_range = ('2000', '2018')\n",
    "crs = \"EPSG:3577\"\n",
    "res = (-30, 30)\n",
    "tide_range = (0.50, 1.00)\n",
    "\n",
    "products = ['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3']\n",
    "measurements = ['nbart_red', 'nbart_green', 'nbart_blue', 'nbart_swir_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'y': y_range,\n",
    "    'x': x_range,\n",
    "    'time': time_range,\n",
    "    'measurements': measurements,\n",
    "    'crs': crs,\n",
    "    'output_crs': crs,\n",
    "    'resolution': res\n",
    "}\n",
    "\n",
    "landsat_ds = load_ard(\n",
    "    dc=dc,\n",
    "    products=products,\n",
    "    group_by='solar_day',\n",
    "    **query\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the timesteps to visualise\n",
    "timestep = 4\n",
    "\n",
    "# Generate RGB plots at each timestep\n",
    "rgb(landsat_ds, \n",
    "    index=timestep,\n",
    "    percentile_stretch=(0.00, 0.95))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_ds = calculate_indices(landsat_ds, index='MNDWI', \n",
    "                               collection='ga_ls_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate tides for each timestep in the satellite dataset\n",
    "landsat_ds = tidal_tag(ds=landsat_ds, tidepost_lat=None, tidepost_lon=None)\n",
    "\n",
    "# Print the output dataset with new `tide_height` variable\n",
    "print(landsat_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the min and max tide heights to include based on the % range\n",
    "min_tide, max_tide = landsat_ds.tide_height.quantile(tide_range) \n",
    "\n",
    "# Plot the resulting tide heights for each Landsat image:\n",
    "landsat_ds.tide_height.plot()\n",
    "plt.axhline(min_tide, c='red', linestyle='--')\n",
    "plt.axhline(max_tide, c='red', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep timesteps larger than the min tide, and smaller than the max tide\n",
    "landsat_filtered = landsat_ds.sel(time=(landsat_ds.tide_height > min_tide) &\n",
    "                                       (landsat_ds.tide_height <= max_tide))\n",
    "print(landsat_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = '1Y'\n",
    "\n",
    "# Combine into summary images by `time_step`\n",
    "landsat_summaries = (landsat_filtered.MNDWI\n",
    "                     .compute()\n",
    "                     .resample(time=time_step, closed='left')\n",
    "                     .median('time'))\n",
    "\n",
    "# Plot the output summary images\n",
    "landsat_summaries.plot(col='time',\n",
    "                       cmap='RdBu',\n",
    "                       col_wrap=4,\n",
    "                       vmin=-0.8,\n",
    "                       vmax=0.8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up attributes to assign to each waterline\n",
    "attribute_data = {'time': [str(i)[0:10] for i in landsat_summaries.time.values]}\n",
    "attribute_dtypes = {'time': 'str'}\n",
    "\n",
    "# Extract waterline contours for the '0' water index threshold:\n",
    "contour_gdf = contour_extract(\n",
    "    z_values=[0],\n",
    "    ds_array=landsat_summaries,\n",
    "    ds_crs=landsat_ds.crs,\n",
    "    ds_affine=landsat_ds.geobox.transform,\n",
    "    output_shp=f'Outputs/contours.shp',\n",
    "    attribute_data=attribute_data,\n",
    "    attribute_dtypes=attribute_dtypes,\n",
    "    min_vertices=50)\n",
    "\n",
    "# Plot output shapefile over the first MNDWI layer in the time series\n",
    "landsat_summaries.isel(time=0).plot(size=12, \n",
    "                                    cmap='Greys', \n",
    "                                    add_colorbar=False)\n",
    "contour_gdf.to_crs(epsg=4326).to_file('Outputs/contours.geojson', driver='GeoJSON')\n",
    "\n",
    "contour_gdf.plot(ax=plt.gca(), \n",
    "                 column='time', \n",
    "                 cmap='YlOrRd', \n",
    "                 legend=True, \n",
    "                 legend_kwds={'loc': 'lower right'})\n",
    "plt.show()\n",
    "\n",
    "print(contour_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute change statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import mapping\n",
    "from shapely.ops import nearest_points\n",
    "from shapely.geometry import Point, LineString, MultiPoint\n",
    "import geopandas as gpd\n",
    "\n",
    "# Read in contours\n",
    "# contours_gdf = gpd.read_file(f'output_data/{study_area}/{study_area}_{water_index}_{index_threshold}.shp')\n",
    "\n",
    "# Set annual shoreline to use as a baseline\n",
    "baseline_year = contour_gdf.index[0]\n",
    "baseline_contour = contour_gdf.loc[baseline_year].geometry\n",
    "\n",
    "# Set up output shapefile\n",
    "schema = {'geometry': 'Point','properties': {'id': 'int'}}\n",
    "baseline_points_shp = f'Outputs/test_statistics.shp' \n",
    "\n",
    "with fiona.open(baseline_points_shp, 'w', 'ESRI Shapefile', schema, crs=contour_gdf.crs) as output:\n",
    "    \n",
    "    # create points every 30 meters along the line\n",
    "    for i, distance in enumerate(range(0, int(baseline_contour.length), 100)):\n",
    "         point = baseline_contour.interpolate(distance)   \n",
    "         output.write({'geometry': mapping(point), 'properties': {'id': i}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(landsat_summaries)\n",
    "print(baseline_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read points in as geopandas\n",
    "points_gdf = gpd.read_file(baseline_points_shp)\n",
    "\n",
    "# Copy geometry to baseline point\n",
    "points_gdf['p_baseline'] = points_gdf.geometry\n",
    "baseline_x_vals = points_gdf.geometry.x\n",
    "baseline_y_vals = points_gdf.geometry.y\n",
    "\n",
    "# Get array of water index values for baseline time period \n",
    "baseline_array = landsat_summaries.isel(time = baseline_year)\n",
    "\n",
    "print(baseline_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all comparison years in contour gdf\n",
    "for comp_year in contour_gdf.index.unique().values:\n",
    "\n",
    "    #print(comp_year)\n",
    "\n",
    "    # Set comparison contour\n",
    "    comp_contour = contour_gdf.loc[comp_year].geometry\n",
    "    \n",
    "    # Find nearest point on comparison contour\n",
    "    points_gdf[f'p_{comp_year}'] = points_gdf.apply(lambda x: \n",
    "                                                    nearest_points(x.p_baseline, comp_contour)[1], axis=1)\n",
    "    \n",
    "    # Compute distance between baseline and comparison year points\n",
    "    points_gdf[f'{comp_year}'] = points_gdf.apply(lambda x: x.geometry.distance(x[f'p_{comp_year}']), axis=1)\n",
    "\n",
    "    # Extract comparison array\n",
    "    comp_array = landsat_summaries.isel(time = comp_year)\n",
    "    \n",
    "    # Convert baseline and comparison year points to geoseries to allow easy access to x and y coords\n",
    "    comp_x_vals = gpd.GeoSeries(points_gdf[f'p_{comp_year}']).x\n",
    "    comp_y_vals = gpd.GeoSeries(points_gdf[f'p_{comp_year}']).y\n",
    "    \n",
    "    # Sample NDWI values from arrays based on baseline and comparison points\n",
    "    baseline_x_vals = xr.DataArray(baseline_x_vals, dims='z')\n",
    "    baseline_y_vals = xr.DataArray(baseline_y_vals, dims='z')\n",
    "    comp_x_vals = xr.DataArray(comp_x_vals, dims='z')\n",
    "    comp_y_vals = xr.DataArray(comp_y_vals, dims='z')   \n",
    "    points_gdf['index_comp_p1'] = comp_array.interp(x=baseline_x_vals, y=baseline_y_vals)\n",
    "    points_gdf['index_baseline_p2'] = baseline_array.interp(x=comp_x_vals, y=comp_y_vals)\n",
    "    \n",
    "    # Compute directionality of change (negative = erosion, positive = accretion)    \n",
    "    points_gdf['loss_gain'] = (points_gdf.index_baseline_p2 > points_gdf.index_comp_p1).astype(int).replace(to_replace=0, value=-1)\n",
    "    points_gdf[f'{comp_year}'] = points_gdf[f'{comp_year}'] * points_gdf.loss_gain\n",
    "    \n",
    "\n",
    "# Get list of cols to keep\n",
    "cols_to_keep = ['geometry'] + [str(val) for val in contour_gdf.index.unique().values]\n",
    "    \n",
    "# Keep required columns\n",
    "points_gdf = points_gdf[cols_to_keep]\n",
    "points_gdf = points_gdf.round(2)\n",
    "\n",
    "print(points_gdf)\n",
    "\n",
    "\n",
    "# print(points_gdf[['geometry']] + contour_gdf.index.unique().values.tolist())\n",
    "# # print(points_gdf)\n",
    "\n",
    "# for val in contour_gdf.index.unique().values.tolist():\n",
    "#     print(val)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "def change_regress(row, x_vals, x_labels, std_dev=3):\n",
    "    \n",
    "    # Extract x (time) and y (distance) values\n",
    "    x = x_vals\n",
    "    y = row.values[1:].astype(np.float)\n",
    "    \n",
    "    # Drop NAN rows\n",
    "    xy_df = np.vstack([x, y]).T\n",
    "    is_valid = ~np.isnan(xy_df).any(axis=1)\n",
    "    xy_df = xy_df[is_valid]\n",
    "    valid_labels = x_labels[is_valid]\n",
    "    \n",
    "    # Remove outliers\n",
    "    outlier_bool = (np.abs(stats.zscore(xy_df)) < float(std_dev)).all(axis=1)\n",
    "    xy_df = xy_df[outlier_bool]\n",
    "        \n",
    "    # Compute linear regression\n",
    "    lin_reg = stats.linregress(x=xy_df[:,0], \n",
    "                               y=xy_df[:,1])\n",
    "    \n",
    "    # Return slope, p-values and list of outlier years excluded from regression   \n",
    "    return pd.Series({'slope': np.round(lin_reg.slope, 2), \n",
    "                      'pvalue': np.round(lin_reg.pvalue, 3),\n",
    "                      'outliers': str(valid_labels[~outlier_bool]).replace('[', '').replace(']', '')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify dates for regression\n",
    "import numpy as np\n",
    "x_years = np.array([int(i[:4]) for i in points_gdf.columns[1:]])\n",
    "\n",
    "print(x_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute change rates\n",
    "rate_out = points_gdf.apply(lambda x: change_regress(x, x_vals = x_years, x_labels = x_years, std_dev=3), axis=1)\n",
    "\n",
    "points_gdf[['mov_rate', 'mov_sig', 'mov_outl']] = rate_out\n",
    "\n",
    "print(points_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CRS\n",
    "points_gdf.crs = str(landsat_ds.crs)\n",
    "\n",
    "# Sort by descending absolute value and export\n",
    "points_gdf.reindex(points_gdf.mov_rate.abs().sort_values().index).to_file(baseline_points_shp)\n",
    "\n",
    "print(points_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_test = points_gdf[['geometry', 'mov_rate']]\n",
    "points_test.crs = {'init' :'epsg:3577'}\n",
    "points_new = points_test.to_crs({'init': 'epsg:4326'}) \n",
    "\n",
    "points_new.to_file('Outputs/contours_rateofchange.geojson', driver='GeoJSON')\n",
    "\n",
    "print(points_new)\n",
    "\n",
    "print(points_new.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(points_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
